# Franka Tray RL

![alt text](image.png)

This repository contains a custom MuJoCo + Gym environment for robotic manipulation with a Franka Panda arm, where the robot holds a tray and must balance/manipulate a cylinder for reinforcement learning research.

    ğŸ“‚ Repository Structure
    franka_tray_rl/
    â”‚
    â”œâ”€â”€ assets/                     # Models & meshes
    â”‚   â”œâ”€â”€ panda_tray/             # Panda + tray assets
    â”‚   â”‚   â”œâ”€â”€ hand.stl
    â”‚   â”‚   â”œâ”€â”€ link0.stl ... link7.stl   # Panda STL meshes
    â”‚   â”‚   â”œâ”€â”€ panda_tray.urdf     # URDF definition of Panda + Tray
    â”‚   â”‚   â”œâ”€â”€ panda_tray_cylinder.xml # MJCF (MuJoCo) with tray + cylinder
    |   â”‚   â”œâ”€â”€ panda_tray_cylinder_camera.xml
    |   â”‚   â””â”€â”€ panda_tray_cylinder_torque.xml
    â”‚   â”œâ”€â”€ panda/
    â”‚   â””â”€â”€ tray/ 
    â”‚
    â”œâ”€â”€ debug/                      # Standalone debugging scripts
    â”‚   â”œâ”€â”€ check_urdf_xml.py       # Check whether urdf and xml is the same - essential for using URDF with pybullet to get IK solutions for XML
    â”‚   â”œâ”€â”€ fk_generator.py         # Generates forward kinematics
    |   â”œâ”€â”€ ik_generator.py         # Generates inverse kinematics
    â”‚   â”œâ”€â”€ interactive_ik.py       # Interactive IK exploration
    â”‚   â”œâ”€â”€ urdf_viewer.py          # Loads URDF in viewer
    â”‚   â””â”€â”€ xml_viewer.py           # Loads XML in MuJoCo viewer
    â”‚
    â”œâ”€â”€ docs/  
    â”‚   â””â”€â”€ TrayPose.md             # Explain TrayPose environment
    |
    â”œâ”€â”€ envs/                       # OpenAI Gym environments
    â”‚   â”œâ”€â”€ torquesensor/           # (Future: Replace cylinder state with noisy torque sensor readings on both horizontal axes [2])
    â”‚   â””â”€â”€ traypose/               # Main tray manipulation environment
    â”‚       â”œâ”€â”€ __init__.py
    â”‚       â”œâ”€â”€ config.yaml         # Config file (parameters)
    â”‚       â””â”€â”€ traypose_env.py     # Core `TrayPoseEnv` class
    â”‚
    â”œâ”€â”€ jointpos/                   # Placeholder for joint position values to define start & goal pose
    â”‚   â””â”€â”€ config.txt              # Tested start and goal position info
    â”œâ”€â”€ scripts/                    # Runnable scripts
    â”‚   â”œâ”€â”€ torquesensor/
    â”‚   â””â”€â”€ traypose/
    |       â”œâ”€â”€ pd_tuning.py            # Grid search for PD parameters
    |       â”œâ”€â”€ test_trainpose.py       # Test train models
    |       â”œâ”€â”€ train_traypose.py       # Train models
    â”‚       â””â”€â”€ visualize_traypose.py   # Demo script with MuJoCo viewer
    â”‚
    â””â”€â”€ training/                   # Folder for RL training data

## ğŸ¦¾ Environment: 
### 1. TrayPoseEnv
- [Document](docs/TrayPose.md)
- [Code](envs/traypose/traypose_env.py)

## âš™ï¸ Setup

    git clone git@github.com:Thinkminator/franka_tray_rl.git
    cd franka_tray_rl

Setup Conda Environment:

    conda env create -f environment.yml
    conda activate franka_tray_rl

## ğŸš€ Running a Env Demo

Visualize the tray-cylinder environment:


    python scripts/traypose/visualize_traypose.py [Mode]


- [Mode] = zero, seeded or random 
    - zero: Zero action mode (arm stays at start pose)
    - random: Random action mode (arm moves randomly)
    - seeded: Random actions with fixed RNG seed for reproducibility

A MuJoCo viewer will open showing the Panda arm holding the tray.
A red cylinder will spawn above the tray.
Random actions will move the tray.

## ğŸ§  Running a Network model (No viewer render)

To see a forward and backward pass with network update:

    python Network/Net_demo.py
    
## ğŸ§  Training a model(Pytorch based, no viewer render)

Perform training loop with Pytorch:

    python Network/Torch_train.py

## ğŸ§  Training a model (SB3, no viewer render)

Perform training loop with Stable Baseline 3:

    python scripts/traypose/train_traypose.py


## ğŸ§  Testing a model (SB3, with viewer render)

To evaluate a model:

    python scripts/traypose/test_trainpose.py


## ğŸ§  Next Steps (RL Training)

Tuning of the hyperparameter and reward structure to ensure valid training 


ğŸ“Œ TODO roadmap
- Add torque-sensor env
- Release pre-trained models
- [Future] Integrate RGB-D camera inputs (depthcamera env) to track cylinder
